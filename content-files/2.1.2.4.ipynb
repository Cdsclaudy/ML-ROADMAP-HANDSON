{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2.4. NAIIVE BAYES CLASSIFIER\n",
    "## DEFINITION\n",
    "**Naive Bayes classifier is a kind of machine learning algorithm that is used for solving classification problems**. It is based on Bayes’ theorem, which is a mathematical formula that calculates the probability of an event based on prior knowledge of related events.\n",
    "\n",
    "## DATASET\n",
    "Naive Bayes classifier is a supervised learning algorithm, which means it requires labeled data for training. The data consists of a dependent variable, which is a categorical variable that can take one of several values, and independent variables, which can be numerical or categorical variables.\n",
    "\n",
    "## GOAL\n",
    "The goal of Naive Bayes classifier is to find the most likely class for a given instance based on the values of the independent variables. It does so by applying Bayes’ theorem to each class and selecting the class with the highest probability.\n",
    "\n",
    "## BAYES THEOREM & NAIIVE BAYES CLASSIFIER\n",
    "Bayes’ theorem states that the probability of an event A given another event B is equal to the probability of B given A multiplied by the probability of A divided by the probability of B. Mathematically, it can be written as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "In Naive Bayes classifier, A is the class and B is the instance represented by the independent variables. Therefore, the probability of a class given an instance is equal to the probability of the instance given the class multiplied by the probability of the class divided by the probability of the instance. Mathematically, it can be written as:\n",
    "\n",
    "$$P(C|X) = \\frac{P(X|C)P(C)}{P(X)}$$\n",
    "\n",
    "where C is the class, X is the instance, P(C) is the prior probability of the class, P(X|C) is the likelihood probability of the instance given the class, and P(X) is the marginal probability of the instance.\n",
    "\n",
    "The term naive in Naive Bayes classifier comes from the assumption that all the independent variables are independent of each other given the class. This means that the likelihood probability of the instance given the class can be calculated by multiplying the probabilities of each independent variable given the class.\n",
    "This means that the likelihood probability of the instance given the class can be calculated by multiplying the probabilities of each independent variable given the class. Mathematically, it can be written as:\n",
    "\n",
    "$$P(X|C) = P(x_1|C)P(x_2|C)...P(x_n|C)$$\n",
    "\n",
    "where $$x_1, x_2, ..., x_n$$ are the independent variables.\n",
    "\n",
    "The marginal probability of the instance can be calculated by summing up the probabilities of all possible classes for that instance. Mathematically, it can be written as:\n",
    "\n",
    "$$P(X) = \\sum_{i=1}^k P(X|C_i)P(C_i)$$\n",
    "\n",
    "where k is the number of classes.\n",
    "\n",
    "To make a prediction for a new instance, Naive Bayes classifier calculates the posterior probability of each class for that instance using Bayes' theorem and selects the class with the highest probability. Mathematically, it can be written as:\n",
    "\n",
    "$$\\hat{C} = \\arg\\max_{C_i} P(C_i|X)$$\n",
    "\n",
    "where $\\hat{C}$ is the predicted class.\n",
    "\n",
    "\n",
    "## ADVANTAGES\n",
    "- It is easy to implement and understand.\n",
    "- It can handle both numerical and categorical variables.\n",
    "- It can perform well with a small amount of training data.\n",
    "- It can handle missing values by ignoring them or using a default value.\n",
    "  \n",
    "## DISADVANTAGES\n",
    "- It assumes that all the independent variables are independent of each other given the class, which may not be true in reality.\n",
    "- It may suffer from overfitting or underfitting if there are too many or too few features.\n",
    "- It may not perform well with highly correlated or multicollinear variables.\n",
    "\n",
    "## APPLICATIONS\n",
    "\n",
    "- **Medical diagnosis**: Naive Bayes classifier can be used to diagnose diseases based on symptoms and test results.\n",
    "- **Customer segmentation**: Naive Bayes classifier can be used to segment customers based on their demographics, preferences, behavior, etc.\n",
    "- **Fraud detection**: Naive Bayes classifier can be used to detect fraudulent transactions based on patterns and anomalies in the data.\n",
    "- **Natural language processing**: Naive Bayes classifier can be used to perform tasks such as sentiment analysis, text classification, part-of-speech tagging, etc.\n",
    "\n",
    "## CONCLUSION\n",
    "In conclusion, Naive Bayes classifier is a simple and effective tool for solving classification problems in machine learning. It has a simple and intuitive structure that can represent complex decisions and outcomes. However, it also has some limitations and challenges that need to be addressed carefully. Naive Bayes classifier is widely used in various domains and applications that require decision making and prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANDS-ON: NAIIVE BAYES CLASSIFIER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "data['species'] = iris['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('species', axis=1)\n",
    "y = data['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PREDICTIONS AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Measure the performance of the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "1. https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
    "2. https://www.javatpoint.com/machine-learning-naive-bayes-classifier\n",
    "3. https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdllab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
